{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 10 texts.\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('test/*.txt')\n",
    "texts = list()\n",
    "for fname in filenames:\n",
    "    with open(fname,'r') as f:\n",
    "        texts.append(f.read())\n",
    "print('read', len(texts), 'texts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; an\n"
     ]
    }
   ],
   "source": [
    "single_text = texts[0]\n",
    "print(single_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cs/student/dcornell/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(single_text)\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.',\n",
       " \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(single_text)\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 191673 words in test/austen-emma.txt\n",
      "found 97888 words in test/austen-persuasion.txt\n",
      "found 141367 words in test/austen-sense.txt\n",
      "found 946812 words in test/bible-kjv.txt\n",
      "found 8239 words in test/blake-poems.txt\n",
      "found 55621 words in test/bryant-stories.txt\n",
      "found 18542 words in test/burgess-busterbrown.txt\n",
      "found 33310 words in test/carroll-alice.txt\n",
      "found 97203 words in test/chesterton-ball.txt\n",
      "found 85412 words in test/chesterton-brown.txt\n"
     ]
    }
   ],
   "source": [
    "for fname,text in zip(filenames, texts):\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    print('found', len(words), 'words in', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 7493 sentences in test/austen-emma.txt\n",
      "found 3654 sentences in test/austen-persuasion.txt\n",
      "found 4833 sentences in test/austen-sense.txt\n",
      "found 29812 sentences in test/bible-kjv.txt\n",
      "found 355 sentences in test/blake-poems.txt\n",
      "found 2715 sentences in test/bryant-stories.txt\n",
      "found 1001 sentences in test/burgess-busterbrown.txt\n",
      "found 1625 sentences in test/carroll-alice.txt\n",
      "found 4624 sentences in test/chesterton-ball.txt\n",
      "found 3712 sentences in test/chesterton-brown.txt\n"
     ]
    }
   ],
   "source": [
    "for fname,text in zip(filenames, texts):\n",
    "    sents = nltk.tokenize.sent_tokenize(text)\n",
    "    print('found', len(sents), 'sentences in', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/austen-emma.txt\n",
      " number: 7493; max words: 275; min words: 1; av words: 25.58054183904978\n",
      "\n",
      "test/austen-persuasion.txt\n",
      " number: 3654; max words: 215; min words: 1; av words: 26.78927203065134\n",
      "\n",
      "test/austen-sense.txt\n",
      " number: 4833; max words: 346; min words: 2; av words: 29.250362093937515\n",
      "\n",
      "test/bible-kjv.txt\n",
      " number: 29812; max words: 564; min words: 2; av words: 31.759425734603514\n",
      "\n",
      "test/blake-poems.txt\n",
      " number: 355; max words: 105; min words: 2; av words: 23.208450704225353\n",
      "\n",
      "test/bryant-stories.txt\n",
      " number: 2715; max words: 135; min words: 2; av words: 20.486556169429097\n",
      "\n",
      "test/burgess-busterbrown.txt\n",
      " number: 1001; max words: 93; min words: 2; av words: 18.523476523476525\n",
      "\n",
      "test/carroll-alice.txt\n",
      " number: 1625; max words: 202; min words: 2; av words: 20.498461538461537\n",
      "\n",
      "test/chesterton-ball.txt\n",
      " number: 4624; max words: 202; min words: 2; av words: 21.021410034602077\n",
      "\n",
      "test/chesterton-brown.txt\n",
      " number: 3712; max words: 115; min words: 2; av words: 23.009698275862068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fname,text in zip(filenames, texts):\n",
    "    sents = nltk.tokenize.sent_tokenize(text)\n",
    "    sent_words = [nltk.tokenize.word_tokenize(s) for s in sents]\n",
    "    \n",
    "    sent_lengths = [len(s) for s in sent_words]\n",
    "    max_len = max(sent_lengths)\n",
    "    min_len = min(sent_lengths)\n",
    "    av_len = sum(sent_lengths)/len(sent_lengths)\n",
    "    \n",
    "    print('{}\\n number: {}; max words: {}; '\n",
    "          'min words: {}; av words: {}'\n",
    "          '\\n'.format(fname, len(sents), max_len, min_len, av_len)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/austen-emma.txt\n",
      "he 0.007121503811178413\n",
      "she 0.009255346345077292\n",
      "\n",
      "test/austen-persuasion.txt\n",
      "he 0.007508581235697941\n",
      "she 0.008366704805491992\n",
      "\n",
      "test/austen-sense.txt\n",
      "he 0.00632396528185503\n",
      "she 0.009429357629432611\n",
      "\n",
      "test/bible-kjv.txt\n",
      "he 0.010207939907816968\n",
      "she 0.0009811873951745436\n",
      "\n",
      "test/blake-poems.txt\n",
      "he 0.004248088360237893\n",
      "she 0.0008496176720475786\n",
      "\n",
      "test/bryant-stories.txt\n",
      "he 0.015677531867460133\n",
      "she 0.006472375541611981\n",
      "\n",
      "test/burgess-busterbrown.txt\n",
      "he 0.030309567468450007\n",
      "she 0.00010786322942508899\n",
      "\n",
      "test/carroll-alice.txt\n",
      "he 0.0029420594416091263\n",
      "she 0.015190633443410387\n",
      "\n",
      "test/chesterton-ball.txt\n",
      "he 0.010791847988230815\n",
      "she 0.0007510056273983313\n",
      "\n",
      "test/chesterton-brown.txt\n",
      "he 0.012246522736851964\n",
      "she 0.0010420081487378823\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "for fname,text in zip(filenames, texts):\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    sort_word_counts = list(sorted(word_counts.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    print(fname)\n",
    "    #print(word_counts['cat'])\n",
    "    print('he', word_counts['he']/len(words))\n",
    "    print('she', word_counts['she']/len(words))\n",
    "    #print(sort_word_counts[:3])\n",
    "    #print(sort_word_counts[-3:])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /cs/student/dcornell/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/austen-emma.txt\n",
      "[('is', 1221), ('have', 1301), ('had', 1605), ('be', 1965), ('was', 2383)]\n",
      "\n",
      "test/austen-persuasion.txt\n",
      "[('been', 495), ('have', 583), ('be', 949), ('had', 1177), ('was', 1330)]\n",
      "\n",
      "test/austen-sense.txt\n",
      "[('is', 732), ('have', 806), ('had', 969), ('be', 1304), ('was', 1846)]\n",
      "\n",
      "test/bible-kjv.txt\n",
      "[('have', 3842), ('said', 3995), ('was', 4515), ('is', 6832), ('be', 6877)]\n",
      "\n",
      "test/blake-poems.txt\n",
      "[('have', 17), ('are', 21), ('be', 25), ('was', 31), ('is', 45)]\n",
      "\n",
      "test/bryant-stories.txt\n",
      "[('were', 194), ('is', 243), ('had', 293), ('said', 452), ('was', 713)]\n",
      "\n",
      "test/burgess-busterbrown.txt\n",
      "[('see', 72), ('did', 78), ('is', 167), ('had', 220), ('was', 287)]\n",
      "\n",
      "test/carroll-alice.txt\n",
      "[(\"'s\", 121), ('be', 145), ('had', 183), ('was', 361), ('said', 456)]\n",
      "\n",
      "test/chesterton-ball.txt\n",
      "[('be', 401), ('had', 556), ('said', 652), ('is', 717), ('was', 926)]\n",
      "\n",
      "test/chesterton-brown.txt\n",
      "[('be', 305), ('said', 415), ('is', 463), ('had', 526), ('was', 1149)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fname,text in zip(filenames, texts):\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    verb_tok = [w for w,p in pos_tags if p.startswith('VB')]\n",
    "    verb_cts = Counter(verb_tok)\n",
    "    sort_verbs = list(sorted(verb_cts.items(), key=lambda x: x[1]))\n",
    "    \n",
    "    print(fname)\n",
    "    #print(pos_tags[:5])\n",
    "    #print(verb_tok[:5])\n",
    "    print(sort_verbs[-5:])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
