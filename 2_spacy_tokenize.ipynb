{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 10 texts.\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('test/*.txt')\n",
    "texts = list()\n",
    "for fname in filenames:\n",
    "    with open(fname,'r') as f:\n",
    "        texts.append(f.read())\n",
    "print('read', len(texts), 'texts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_text = texts[0]\n",
    "print(single_text[:48])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse a Single Document\n",
    "\n",
    "Now, we will import a text model using spacy. The [spacy install instructions](https://spacy.io/usage) are a bit more complicated than other software, but the software is extremely powerful when installed.\n",
    "For me, the model installation required only one command:\n",
    "\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f9e982cdf28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[, Emma, by, Jane, Austen]\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(single_text)\n",
    "tokens = [t for t in doc]\n",
    "print(tokens[:5])\n",
    "token_str = [t.text for t in doc]\n",
    "print(token_str[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas\n",
    "Lemmas are essentially base words. See a full explanation on the [Stanford NLP page](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'volume', '-PRON-', '\\n\\n', 'chapter', '-PRON-', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seem', 'to', 'unite', 'some', 'of', 'the', 'good', 'blessing', '\\n', 'of', 'existence', ';', 'and', 'have', 'live', 'nearly', 'twenty', '-', 'one', 'year', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', '-PRON-', '.', '\\n\\n', '-PRON-', 'be', 'the', 'young', 'of', 'the', 'two', 'daughter', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'have', ',', 'in', 'consequence', 'of', '-PRON-', 'sister', \"'s\", 'marriage', ',', '\\n', 'be', 'mistress', 'of', '-PRON-']\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'VOLUME', 'I', '\\n\\n', 'CHAPTER', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', '\\n', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'been', 'mistress', 'of', 'his']\n"
     ]
    }
   ],
   "source": [
    "lemmas = [t.lemma_ for t in doc]\n",
    "print(lemmas[:100])\n",
    "print(token_str[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('two', 127),\n",
       " ('one', 143),\n",
       " ('first', 169),\n",
       " ('Jane', 184),\n",
       " ('Woodhouse', 287),\n",
       " ('Knightley', 315),\n",
       " ('Elton', 370),\n",
       " ('Weston', 424),\n",
       " ('Harriet', 438),\n",
       " ('Emma', 799)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents = [e for e in doc.ents]\n",
    "ent_str = [e.text for e in doc.ents]\n",
    "#ent_types = [(e.text,e.ent_type_) for e in doc.ents]\n",
    "ent_cts = Counter(ent_str)\n",
    "sort_ents = list(sorted(ent_cts.items(), key=lambda x: x[1]))\n",
    "sort_ents[-10:]\n",
    "#print(ent_str[:5])\n",
    "#print(ent_types[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
